\section{State of the art}\label{sec:state-of-the-art}
\subsection{Performance evaluation of Edge Computing systems}
\subsubsection{Analytical modeling and simulation approaches}

The performance evaluation of Edge Computing deployments is a daunting task.
One reason for this is the inherent complexity of modeling such intricate systems, which often involve multiple layers of proxies, load balancers, virtualized computing instances, and networking functions.
The dynamic nature of Edge Computing deployments, with their distributed architectures and diverse set of devices, makes it difficult to develop accurate models that capture the complexities of real-world deployments.

Nevertheless, a small body of works has attempted to tackle this challenge through analytical approaches.
Examples include~\cite{chen2015efficient,champati2015one,champati2016semi,al2017reliable}.
In~\cite{chen2015efficient}, the authors formulate the problem of computation offloading in \gls{MEC} as a multi-user computation offloading game, and design a distributed computation offloading algorithm that achieves a Nash equilibrium to solve it.
They demonstrate through numerical results that the proposed algorithm achieves good computation offloading performance and has good scaling capabilities.
Another work that tackles computation offloading is~\cite{champati2015one}, in which the authors propose a novel optimization algorithm for the cost optimization of hybrid clouds.
The algorithm selects tasks for remote computation on the public cloud based on their estimated processing times and the known cost of offloading them; tasks with large processing times that offset their offloading cost are offloaded.\@
\cite{champati2016semi} proposes semi-online algorithms to to minimize the time required to complete all computational tasks in a sequence, with communication delay, in Cloud Computing environments.
This is achieved by optimizing the scheduling of independent tasks with unknown processing times.
Finally, the authors of~\cite{al2017reliable} propose a model-based rate adaptation algorithm for scalable video streaming in multihop wireless networks.
The algorithm is built on a novel performance model based on stochastic network calculus and allows fast near-optimal rate adaptation for fixed transmission paths and cross-layer optimized routing.

Although these works represent valuable contributions to literature, they present significant limitations to their realism and applicability to \glspl{CPS} and \gls{XR} enabled by Edge Computing.
In~\cite{chen2015efficient,champati2016semi}, the authors assume that task computation times are unknown, and estimate them based on the size of their associated data.
However, applications such as \glspl{NCS} and \gls{MAR} tend to have mostly constant data sizes, with computation times depending strictly upon the semantic content of the inputs.\@
\cite{champati2016semi,al2017reliable} assume independent tasks, but in interactive, feedback-loop-based applications, tasks are intrinsically ordered and dependent on previous tasks.
In~\cite{champati2015one}, the authors propose canceling and re-scheduling a task as a viable scheduling strategy; however, in \glspl{CPS} the canceling of a control task could lead to catastrophic harm to equipment and/or human beings.

Approaches to performance evaluation of distributed systems using simulations also exist in literature, particularly geared towards the Cloud~\cite{mansouri2020cloud}.
Examples of such approaches include the \emph{CloudSim}, \emph{iCanCloud}, and \emph{GreenCloud} simulators.
CloudSim~\cite{calheiros2011cloudsim} is a widely used event-based simulation toolkit designed for generic \gls{IaaS} Cloud Computing environments.
iCanCloud~\cite{nunez2012icancloud} similarly focuses on simulating \gls{AWS} \gls{EC2} compute infrastructure, the project's primary objectives being performance and scalability of simulations.
GreenCloud, on the other hand, is built upon the \acs{ns2}~\cite{nsnam} network simulator and specifically captures energy consumption details of datacenter components and communication patterns between these.

However, these simulators are not suitable for Edge Computing research as they do not fully capture the unique characteristics of Edge environments.
They do not account for the tight integration of compute and network in Edge Computing and only coarsely approximate network effects on workloads.
In these Cloud Computing simulators, end-to-end transmission delays are often treated as static values;
however, the dependency on wireless interfaces in Edge Computing requires a much more detailed modeling of the network.
This includes considerations for mobility, a key characteristic of users in an Edge context which is not accounted for in any of the above tools.
Moreover, existing models for Cloud workloads are unsuitable for Edge Computing research, as Edge workloads present compute characteristic which are wholly distinct from traditional Cloud workloads.
Cloud workloads tend to be stateless and long-lived, whereas Edge workloads are context-sensitive and ephemeral.

A number of simulation approaches specifically targeted toward Edge Computing and which aim to overcome these limitations have therefore emerged in later years~\cite{svorobej2019simulating}.
\emph{iFogSim}~\cite{gupta2017ifogsim}, for instance, is an extension of CloudSim~\cite{calheiros2011cloudsim} geared towards the simulation of \gls{IOT} Fog environments by modeling components such as sensors, actuators, Fog nodes, as well as the Cloud.
Although iFogSim allows for location-aware servicing of user-devices by Fog nodes, this information is static during a simulation, and no mobility of users is considered.
Network links in iFogSim also do not account for the effects on network load on network times, further limiting the simulator's realism.\@

\emph{EdgeCloudSim}~\cite{sonmez2018edgecloudsim} also extends CloudSim~\cite{calheiros2011cloudsim} and provides a much more comprehensive simulation environment for Edge deployments, which includes mobility, network, and edge compute models.
However, the models chosen limit the realism of the tool, as they may not be applicable to all applications classes.
The compute model, for instance, assumes offloading to \glspl{VM}, which does not match the current broad understanding that Edge Computing applications will rely on more flexible and lightweight forms of offloading, such as serverless functions and containers.
Moreover, the tool is highly complex and requires extensive domain knowledge in both communication networks and compute modeling to use effectively.

Finally, another example is \emph{FogNetSim++}~\cite{qayyum2018fognetsimpp}, a tool which builds upon the \acs{OMNET} network simulator.
FogNetSim++ allows users to simulate large Fog networks while incorporating mobility and scheduling models.
However, the tool does not include support for compute (either \gls{VM}- or container-based) migration within the network, a limitation which impacts the ability to accurately and simulate more complex scenarios in Fog and Edge Computing.

It is clear then that, while there have been efforts to develop simulation approaches for evaluating the performance of Edge environments, existing approaches still fall short in capturing sufficient realism for accurate performance evaluation.
Works such as iFogSim, EdgeCloudSim, and FogNetSim++ have attempted to address the limitations of traditional simulation approaches by incorporating components such as mobility, network, and compute models.
However, these approaches have their own limitations, such as unrealistic network load effects or assumptions about offloading technologies.
These limitations impact the ability to accurately simulate the dynamic and complex nature of Edge environments, including the unique challenges posed by complex applications such as \gls{XR} and \glspl{CPS}.
These applications are interactive, real-time, present non-linear behaviors, and, in the case of \gls{XR}, involve human interaction, all factors which are adequately captured by existing simulation approaches.

\subsubsection{Experimental research}

% This dissertation complements existing work on benchmarking distributed system architectures.
% A rich body of literature exists with examples of such approaches for Cloud computing.
% For example, the \gls{YCSB}~\cite{cooper2010benchmarking} is a data-intensive benchmark for the profiling of datacenters and Cloud services; workload characterization in datacenters leads to a similar benchmark in~\cite{jia2013characterizing}.
% In~\cite{turner2012cmart}, the authors introduce \emph{C-MART}, a benchmark for modern web applications running on the Cloud.
% The benchmark utilizes modern web technologies, can be deployed automatically at a large scale, and includes generators that mimic remote clients accessing the system over the internet.\@
% \cite{malawski2018benchmarking,back2018using} focus instead on serverless computing, using compute-intensive workloads to benchmark major Cloud function providers such as \gls{AWS}, Microsoft Azure, and \gls{GCP}.

% As evidenced by the given examples, existing approaches to Cloud benchmarking tend to focus heavily on large-scale data processing and downlink transmission in Cloud scenarios.
% This makes them unsuitable for Edge Computing, as they fail to account for important characteristics of this paradigm, such as latency-sensitivity of workloads and uplink-heavy network traffic.

A number of works have attempted to tackle the challenge of experimentally evaluation performance of Fog and Edge deployments, such as 
\begin{inlineenum}
    \item \emph{EdgeBench}~\cite{das2018edgebench}
    \item \emph{IoTBench}~\cite{lee2019iotbench}
    \item \emph{OpenRTiST}~\cite{george2020openrtist}
    \item \emph{DeFog}~\cite{mcchesney2019defog}
    \item \emph{ComB}~\cite{baurle2022comb}
\end{inlineenum}.
\emph{EdgeBench}~\cite{das2018edgebench} corresponds to a benchmarking suite for the Edge which emulates three different workloads (speech-to-text, image recognition, and sensor network application traffic), specifically targeting serverless deployments.
For each workload, a corresponding batch of data is processed on an Edge node, and results are pushed to the cloud;
cloud-only variants of the workloads also exist.
\emph{IoTBench}~\cite{lee2019iotbench} is a similar benchmarking tool for Edge-deployed \gls{IOT} applications.
It includes seven representative workloads, and allows researchers to evaluate the performance of these applications on Edge infrastructure through the analysis of computational demands and resource consumption.
Both EdgeBench and IoTBench focus exclusively on benchmarking of compute in Edge and Fog deployments, and thus do not represent comprehensive evaluations of performance including network effects in Edge Computing.

\emph{OpenRTiST}~\cite{george2020openrtist} is a tool for the benchmarking and performance evaluation of Edge Computing deployments using real-time processing of a live video feed.
Video is streamed from a source Android device to a compute node where neural style-transfer~\cite{gatys2016image} is applied to it.
The transformed video is then fed back to the source to be presented, resulting in a compute-intensive, bandwidth-hungry, and latency-sensitive benchmark.
However, OpenRTiST is limited by its non-replaceable workload which only targets machine learning-enhanced video processing and analytics.

\emph{DeFog} and \emph{ComB} represent more flexible and comprehensive tools for Edge performance evaluation.
DeFog~\cite{mcchesney2019defog} corresponds to a benchmarking suite for the comparison of deployments on the Edge, Fog, or Cloud.
It includes six latency-critical and bandwidth-intensive workloads built on containers, including real-time video detection and a text-to-speech application.
ComB~\cite{baurle2022comb} is a flexible and extensible application-oriented benchmarking suite for Edge computing.
In opposition to existing approaches, ComB relies on real representative applications instead of synthetic workloads.
It features a built-in distributed video-analytics application that can easily be replaced.
However, although valuable contributions, these works leverage static workloads that fail to account for the intensely dynamic nature of \gls{CPS} and \gls{XR} deployments.

Finally, although some of the above approaches address some of the additional challenges to benchmarking \gls{XR} on the Edge, none of them have tackled the topic in a comprehensive way.\@
\cite{das2018edgebench,mcchesney2019defog,baurle2022comb,george2020openrtist} all target image or video recognition or manipulation in some manner, but none of these approaches have considered the interactive component of \gls{MAR} particularly when it comes to human behavior and its relationship to system responsiveness and performance.

\medskip

The last few years have also seen the emergence of a number of small- to mid-scale platforms and testbeds for Edge Computing research.
Several of these are additionally driven by research interests in novel mobile networking technologies and \gls{MEC}, as well as in the virtualization of network functions.
Of particular interest to us are the
\begin{inlineenum}
    \item \acs{GENI}
    \item Chameleon
    \item \acs{COSMOS}
    \item \acs{POWDER}
    \item \acs{ARA}
    \item EdgeNet
%    \item Drexel Grid \gls{SDR}
\end{inlineenum} testbeds.

\gls{GENI}~\cite{berman2014geni,gosain2017geni} is a testbed deployed across more than fifty sites across the \gls{USA}.
It combines local Edge compute resources with mobile network last-hop connectivity for \gls{MEC} experimentation, with wireless-capable sites incorporate single-hop access to compute, storage, and network resources.
The Chameleon testbed is a research platform originally designed for the study and evaluation of Cloud computing systems~\cite{keahey2020lessons}, but which has recently been expanded to target Edge Computing research through the \acs{CHI}@Edge~\cite{chiatedge} project.
The testbed provides a flexible and reconfigurable infrastructure for researchers to experiment with hardware and software resources, including servers, storage systems, and networking equipment.
\gls{COSMOS} is a \gls{MEC} testbed deployed in New York City (State of New York, \gls{USA}), containing over \num{200} rooftop, intermediate, and mobile nodes.
The system includes \glspl{SDR}, \si{\milli\meter}-wave equipment, optical fibers, Cloud integration, and Edge compute for core network functionality and application data processing~\cite{yu2019cosmos,raychaudhuri2020challenge}.
\gls{POWDER}~\cite{breen2020powder} features roughly \num{15} fixed programmable radio nodes distributed across a \SI{15}{\kilo\meter\squared} area in Salt Lake City (State of Utah, \gls{USA}).
These radio nodes are combined with Edge-based compute nodes as well as Cloud resources for full \gls{MEC} experimentation.
\gls{ARA} includes a broad range of wireless technologies deployed through both \glspl{SDR} and programmable \gls{COTS} radios, as well as automated ground vehicles, cameras and sensors and and spans a rural area with a diameter of over \SI{60}{\kilo\meter}~\cite{zhang2022ara} in Iowa, \gls{USA}. 
Its core goal is the study and deployment of advanced Edge Computing and wireless platforms and technologies in real-world agricultural and rural settings.
EdgeNet deviates from the approaches described above and represents a fully software-based, massively distributed public platform for Edge Computing research~\cite{cappos2018edgenet,senel2021edgenet1,senel2021edgenet2} based on the widely adopted Kubernetes~\cite{kubernetes} framework.
A similar, closely-related project is KubeEdge~\cite{xiong2018extend}, a software framework for extending Kubernetes clusters from the Cloud to the Edge.

Finally, a number of other, small-scale approaches also exist.
In~\cite{gedawy2016cumulus}, the authors propose Cumulus, a prototype testbed for Edge compute offloading in \gls{IOT} with the explicit goal of providing a generic and heterogeneous platform for Edge Computing research.
The authors of~\cite{rimal2018experimental} propose an experimental testbed for two-tiered Edge architectures in the context of \gls{FIWI} Edge Computing.
This testbed is then employed to validate wireless access and compute resource scheduling strategies in these systems.
In~\cite{yamanaka2021design}, the authors present an experimental Edge Computing testbed capable of determining the offload location of a workload based on desired latency parameters.
\cite{diao2019scalable} propose yet another Kubernetes-based testbed based for Edge task offloading based on heterogeneous hardware including low-power single-board computers such as Raspberry Pis and Jetson Nanos.
% \cite{moorthy2022cloudraft} proposes \gls{CLOUDRAFT}, a Cloud-based framework for mobile network experimentation, with a focus on simplifying the management of testbed resources.
% The goal of this project is to integrate, coordinate, share, and improve upon existing testbeds through a common interface.

Although the aforementioned testbeds represent valuable and powerful tools, the lack of a unified approach to testbed management and automation hinders the development and implementation of next-generation wireless systems, Cloud, and Edge computing paradigms.
General-purpose, hardware-agnostic software frameworks such as \gls{CLOUDRAFT}~\cite{moorthy2022cloudraft}  can simplify the management and automation of testbeds, promote compatibility with Cloud- and Edge-native standards, and facilitate collaboration among research groups.
\gls{CLOUDRAFT} is a Cloud-based framework for mobile network experimentation with the goal integrate, coordinate, share, and improve upon existing testbeds through a common interface.
There is still remains much work to be done in this area, particularly with respect to the adoption of Edge-compatible solutions that can enable faster and more reliable experimentation.

\subsection{Experimental research in \glsfmtshort{MAR} and \glsfmtshort{CPS}}

\subsubsection{Experimental research in \glsfmtlong{MAR}}\label{sec:relwork:xremulation}

\gls{MAR} is difficult to model or simulate due to its dynamic and interactive nature involving ``humans-in-the-loop''.
\gls{MAR} experiences are highly dependent on real-time interactions between the user, the virtual objects, the communication network, the computation node, and the real-world.
These interactions are exceedingly challenging to accurately model and reproduce in controlled, simulated, environments.
As a result, the vast majority of research in this field employs experimental approaches to performance evaluation.
Although simulation and model-based approaches such as~\cite{liubogoshchev2021adaptive,sundararajan2021performance} exist, they are far and few in between, and generally target specific use-cases.
Performance evaluation in this field relies instead broadly on real-world experiments and benchmarks are conducted to evaluate the actual performance and user experience of \gls{MAR} applications in real-world conditions, providing more accurate and reliable results.

Examples of such experimental research include~\cite{williams2013transform,munro2016aaremu,george2020openrtist,choi2022emulating,chetoui2022arbench}.
In~\cite{williams2013transform}, the authors introduced a trace-based toolkit for the evaluation of tracking algorithms in \gls{AR} research and development.
The trace consists of geographical coordinates and accelerometer data as well as video frames which can be replayed on a desktop visualization tool or a smartphone application for the evaluation of tracking algorithms in \gls{AR} research and development.\@
\cite{munro2016aaremu} presents a trace-based framework that allows a previously recorded trace of inputs to be replayed to the processing components of a real \gls{MAR} application by mocking Android \gls{SDK} \glspl{API}.
This approach allows for benchmarking and evaluation of algorithms and architectures on real data.
The previously mentioned~\cite{george2020openrtist} approximates the workload generated by a \gls{MAR} on an Edge Computing deployment by performing real-time style-transfer on a live video feed. 
A similar approach to~\cite{munro2016aaremu} was taken by~\cite{choi2022emulating}, but the authors instead provided developers of \gls{AR} with a framework that abstracts input into general classes, allowing for device-agnostic processing.
Finally, the authors of~\cite{chetoui2022arbench} employ \gls{AR} emulation to evaluate hardware rather than the software implementation itself.
Their tool, \emph{ARBench}, features emulated \gls{AR} workloads that mimic the load placed on the system by real applications.

While the above approaches to performance evaluation and research in \gls{MAR} are steps in the right direction, they fail to consider the dynamic nature of \gls{MAR}.
The use of rigid traces in trace-based approaches can lead to timing mismatches when replaying at runtime, as the system may respond differently to the same input depending on factors such as system load and network congestion.
Additionally, these approaches do not take into consideration the effects of system responsiveness on human behavior, which can be critical for evaluating both \gls{QoS} and \gls{QoE}.
To address these issues, future approaches will need to adapt trace replay at runtime to match expected behaviors and consider the impact of system responsiveness on user behavior.
By doing so, we can develop more accurate and reliable benchmarks for \gls{MAR} applications and improve our understanding of how users interact with these technologies.

\subsubsection{Experimental approaches to research in \glsfmtlongpl{NCS}}

A significant amount of work has been dedicated to the modeling and performance characterization of \glspl{NCS} due to their potential benefits for industrial and commercial settings~\cite{lu2016real,hespanha2007survey,zhang2013network,zhang2016survey}.
Research in \glspl{NCS} has mostly focused on addressing the challenges imposed by the introduction of best-effort communication networks into traditional control systems.
Network delays (latency), losses, and \emph{jitter} --- referring to the variation in random network delays --- are at the forefront of these challenges.
They have partially been addressed through the clever placement of the controller (e.g.\ by employing Edge Computing)~\cite{sasaki2017layered,sasaki2016vehicle}, as well as through the development of control algorithms capable of accounting for the effects of the network~\cite{zhang2013network}.

Most of the large literature concerning \glspl{NCS}, however, follows a theoretical approach, with only small fraction of it dealing with experimental studies~\cite{zhang2019networked}.
\gls{NCS} studies are complex due to the inter-domain nature of these systems, requiring expertise in the fields of communication networks, computing, and control theory.
However, theoretical approaches can only capture network behaviors at a coarse level, and thus a body of works has emerged in later years involving experimental approaches to \gls{NCS} benchmarking.

We identify two main approaches: fully practical and partially-emulated approaches.
In a fully practical approach, the experimental setup uses real systems and hardware to test and validate the performance of the \gls{NCS}.
Examples of the application of this approach can be found in studies such as~\cite{drew2005networked,baumann2018evaluating,li2014wireless,cuenca2019periodic}.
These studies implemented wireless and microcontroller-based systems for control and validated them on a physical prototype.
In~\cite{drew2005networked}, the authors present a \gls{NCS} model which considers both random packet delay and loss on both the sensor and actuator sides of the feedback loop.
They validate their design on a physical testbed consisting of inverted pendula controlled from a central computation point over Wi-Fi.
A similar testbed is employed for validation in~\cite{baumann2018evaluating}, in which the authors develop an evaluation methodology for wireless \gls{NCS}.\@
\cite{li2014wireless} implements a wireless microcontroller-based system for vibration control and validates it on a physical prototype comprising a cantilever beam controlled using an \acs{IEEE} 802.15.4 \gls{WPAN} system.\@ \cite{cuenca2019periodic} discusses the design and implementation of a periodic event-triggered sampling and dual-rate control techniques for wireless control, and validate their contributions on a four-rotor autonomous drone platform controlled over WiFi.
\emph{NCSbench}~\cite{zoppi2020ncsbench}, an open-source \gls{NCS} benchmarking platform designed with reproducibility in mind built using the \citetitle{LEGOMindstormsEV3}~\cite{LEGOMindstormsEV3} platform, is another such example.

Partially-emulated approaches, including network and hardware-in-the-loop approaches and which aim to strike a balance between realism and efficiency, have on the other hand also been employed in literature.
Network-in-the-loop refers to experimental setups in which the \emph{network} is instead simulated or emulated.
Such approaches have, for instance, been used to study the effects of the \gls{CSMA/CD} medium access control mechanism on plant stability, as in~\cite{natale2004inverted}.
Hardware-in-the-loop approaches, referring to \gls{NCS} setups in which a real network interacts with a simulated or emulated control system, are particularly prevalent in the field of \emph{smart grid} control.
An example of the application of such an approach can be found in~\cite{wang2020inverter}, in which the authors introduce and validate a novel three-level coordinated control method for photovoltaic inverters.

To the best of our knowledge, there exist currently no generic, hardware-independent framework available for repeatable experimental research in Edge-bound \glspl{NCS}.
While there has been some notable work in this area, such as the work by~\cite{zoppi2020ncsbench}, existing contributions still mostly rely on proprietary and hardware that is difficult to acquire.
This limitation restricts the accessibility of the framework to researchers and practitioners, hindering the reproducibility and comparability of experimental results.
Moreover, the existing research's reliance on hardware also poses scalability limitations.
As the field of Edge Computing-enabled \glspl{NCS} continues to evolve, there is a growing demand for scalable solutions that can be easily adapted to different hardware configurations and setups.
A software-based framework that provides a flexible and scalable solution for performance evaluation of \glspl{NCS} in Edge-native contexts is currently lacking in the field.
