This thesis presents a comprehensive study on latency-sensitive applications in Edge Computing.
The primary contribution of this research is a methodology for analyzing and evaluating the performance of these applications.
The methodology is validated through the examination of two initial case studies, \gls{WCA} and \glspl{NCS}.
In addition to the methodology, this thesis includes several other key contributions.
A prototype testbed and accompanying software framework have been developed to provide a platform for conducting experiments in Edge Computing.
Furthermore, a further deeper exploration into the \gls{WCA} case studied yielded the first-ever model of human behavior in \gls{WCA}, which is a significant advancement in the field.
The methodology, the case studies, and the prototype testbed provide valuable insights into the performance of latency-sensitive applications in Edge Computing and can be used as a basis for future research in this area.

\section{A methodology for the study of latency-sensitive applications in Edge Computing}\label{summary:methodology}

This thesis makes a contribution to the field of Edge Computing by investigating the applications of a methodology for the study of latency-sensitive applications deployed on Edge infrastructure.
These applications, such as \gls{WCA} and \glspl{NCS}, are challenging to study and scale due to their cyber-physical nature, complexity, and requirements for low latency and high reliability.

The main focus of this thesis is to enhance the accuracy and realism of results related to Edge infrastructure, particularly in regard to the network.
The proposed methodology aims to provide a more comprehensive and realistic assessment of the performance of these latency-sensitive applications, allowing for a better understanding of the strengths and limitations of Edge Computing in this context.
Our results will contribute to the development of new techniques and approaches for improving the performance and reliability of Edge Computing systems.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Figs/methodology}
    \caption{%
        Overview of the proposed methodology for the study of latency-sensitive systems on edge computing infrastructure.
        The  client side of the system is replaced with an emulation executed on a general-purpose computing device.
        The backend/server side of the system along with the network remain unchanged.
    }\label{fig:methodology}
\end{figure}

Our methodology is based on the emulation of target workloads on actual Edge infrastructure;
see \cref{fig:methodology}.
We replace the client side of the system with a realistic emulation of the desired behaviors;
this emulation is implemented in software deployed on \gls{COTS} general-purpose computing devices.
In our initial implementation, these correspond to low-cost, easily replaceable and scalable Raspberry Pi 4 Model B~\cite{raspberrypi} \glspl{SBC}.
We aim to maintain the backend software and hardware, as well as the network, unchanged with respect to the real-world deployment, in order to preserve as much realism as possible in the effects arising from the hardware and network.

As discussed in \cref{chap:relatedwork}, most research in this field falls into either simulated or fully-practical real-world approaches.
Our emulated methodology presents several advantages over these alternatives.
To begin with, and perhaps most importantly, it makes our approach portable and applicable to real edge computing deployments.
By limiting the emulation to the workload, our approach can be directly employed on pre-existing edge computing infrastructure in order to benchmark applications before they are deployed.
This makes our approach valuable to not only to the research community, but also to system designers and application developers.

In hand with the previous point, it allows for easier scaling compared to real-world studies.
The systems we target exhibit a centralized nature in which a potentially large number of clients offload computation to a single central compute node.
The client-side component of the applications of interest for this research is often complex to scale.
Consider a system owner interested in studying the performance of some edge computing setup for latency-sensitive applications.
In the case of interactive and immersive applications, scaling the number of human users is a significant challenge, as recruiting participants is an expensive and time-consuming endeavor.
Scaling applications involving \glspl{CPS} such as \glspl{NCS} can be prohibitively complex and expensive depending on the specific hardware involved.
In many cases, these systems are made-to-order, further increasing the cost as economies of scale cannot be employed.
On the other hand, a simulated approach requires modeling not only the application workload, but also the edge computing system and infrastructure.
Due to the intricate nature of contemporary cloud and edge computing setups, which frequently involve multiple tiers of proxies, load balancers, virtualized computing units, and network functions, the modeling of such systems can quickly become an overly complex endeavor.

Our approach circumvents both of these limitations.
Emulating the workload component reduces complexity by moving it into the software domain, allowing for easier scaling through the use of cheap, \gls{COTS} general-purpose hardware such as the aforementioned \glspl{SBC}.
Furthermore, it preserves the realism of effects stemming from the hardware and network.
Employing emulations allows our methodology to realize a more realistic testing environment than a simulated approach and can provide results that are closer to what would be seen in the real-world.
Of particular interest to us are effects due to network factors such as contention, congestion control, and medium access.
These effects are often of stochastic or chaotic natures, and are thus complex to capture in simulations.

Emulating the workload also provides improved repeatability and replicability.
Repeating a study becomes a matter of re-running the workload on the same testbed;
in turn, studies can be replicated simply by obtaining the same or equivalent software workload and deploying it on a comparable testbed.
These are complex tasks to accomplish in real-world approaches, particularly when dealing with humans.

Finally, our methodology improves extensibility significantly.
Replicating the methodology for other workloads simply requires developing a new piece of software to emulate the new workload.
This can further be simplified by employing software platforms for the emulation of categories of workloads, as well will discuss later on in this thesis.

\medskip
In the following subsections we will discuss two illustrative case studies for our methodology; \acl{WCA} and \acl{NCS} research and benchmarking.
\Cref{summary:methodology:usecase_wca} discusses the application of our methodology to \gls{WCA}.
This work was originally published in \cref{paper:olguinmunoz2018demoscaling,paper:olguinmunoz2019edgedroid}.
Next, in \cref{summary:methodology:usecase_ncs} we expand this discussion to \glspl{NCS}, a discussion originally approached in \cref{paper:olguinmunoz2022cleave}.

\subsection{Case study: \acl{WCA}}\label{summary:methodology:usecase_wca}

\begin{figure}
    \centering
    \begin{subfigure}[b]{.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figs/trace_edgedroid}
        \caption{%
            High level conceptual design of our methodology for \gls{WCA}.
            We replace the human by a trace-driven emulation.
            This allows us to maintain realism in inputs sent over the network to the compute process on the backend, while simplifying the design of the client software.
        }\label{fig:methodology:wca:conceptual}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{publications/2018DemoScalingOnTheEdge/img/TraceReplay_GenArch}
        \caption{%
            Architectural overview of the EdgeDroid \num{1.0} tool.
            The ``client emulator app'' implements the aforementioned user model together with the required networking functionality to connect to a \gls{WCA} backend running on a cloudlet.%
        }
    \end{subfigure}\\
    \medskip
    \begin{subfigure}[t]{\textwidth}
        \centering
        \adjustbox{scale=0.7}{
            \begin{tikzpicture}[align=center,
                node distance=.5cm and 1.5cm,
                every initial by arrow/.style={-{Latex[length=2mm]}}]
                % Place nodes
                \node [initial, state, minimum size=6em, initial text=] (play) {Play};
                \node [state, above right=of play, minimum size=6em] (change) {Change\\step};
                \node [state, below right=of play, minimum size=6em] (rewind) {Rewind};
                \node [state, accepting, above right=of rewind, minimum size=6em] (shutdown) {Shutdown};

                % Draw edges
                \path[draw, -{Latex[length=2mm]}]
                (play) edge [bend right=20] node[left] {Step done} (rewind)
                edge [bend left=20] node[left] {Got feedback\\(\emph{positive})} (change)
                edge [out=140,in=220,looseness=6] node[left] {Step\\not done} (play)

                (change) edge [bend left=20] node[right] {Step changed} (play)
                edge [bend left=20] node[right] {All steps done} (shutdown)

                (rewind) edge [bend right=20] node[right] {Rewound} (play)
                edge [bend right=20] node[right] {Too many rewinds} (shutdown);

            \end{tikzpicture}
        }
        \caption{State diagram of the user model governing the replay of the pre-recorded trace at runtime. This model approximates the behavior of an ``ideal'' human, one that is patient and makes no mistakes.}\label{fig:usermodel}
    \end{subfigure}
    \caption{%
        Overview of our first implementation of the methodology for \gls{WCA}.
        Figures originally published in \cref{paper:olguinmunoz2019edgedroid}.
    }
\end{figure}

We first introduce our methodology and its applicability to \gls{WCA} in \cref{paper:olguinmunoz2018demoscaling,paper:olguinmunoz2019edgedroid}.
The former corresponds to an extended abstract paper which discusses a high level overview of our approach;
the latter presents a deeper, more complete discussion about the implementation together with some first experimental results.
As discussed in \cref{chap:introduction}\todo{Was it really here?}, the main challenge to benchmarking \gls{WCA} --- and other ``human-in-the-loop'' applications on the edge --- concerns the involvement of human beings in their operation.
Humans are unreliable, and, perhaps more importantly, hard to scale.

The implementation of the client-side emulation necessary for our methodology follows in these works a trace-based design.
\Cref{fig:methodology:wca:conceptual} presents a diagram of our conceptual approach to this implementation.
We introduce a tool, \emph{EdgeDroid \num{1.0}}, which replays a pre-recorded trace of sensory inputs to the original \gls{WCA} backend.
The tool is implemented in Android, allowing for its easy deployment on the same kind of \gls{COTS} mobile and/or wearable devices (e.g.\ Google Glass~\cite{googleglass}) on which real \gls{WCA} applications are intended to run in the future.
Furthermore, this tool is instrumented, allowing us to collected a multitude of system-level metrics at runtime which can then be analyzed.
On the other hand, the trace in question corresponds to a pre-recorded sequence of sensory inputs obtained from a real execution of the \gls{WCA} by a human volunteer.
The trace is recorded in a near-ideal setting, such that it does not include either human mistakes or segments with degraded system responsiveness.
Once recorded, the trace is manually segmented into the logical component steps of the task, and these are replayed in sequence back to the backend by the EdgeDroid tool.

We opt for a trace-based approach for our first implementation of the methodology for \gls{WCA} for three key reasons.
The first of these is the level of realism if affords in terms of the payloads sent over the network and, in particular, processed by the backend.
Using a trace ensures that the same computation is performed on the edge as if a human was involved, while also ensuring a reproducible application execution path.

The second is simplicity, as such an approach does not require complex modeling of human behavioral patterns, merely the observation and recording of them.
Compatible traces can be easily obtained simply by instrumenting existing \gls{WCA} client applications to record all captured inputs.

The final advantage corresponds to extensibility.
As long as the tasks belong to the same category of \gls{WCA} applications (in this case, step-based cognitive assistance), using a trace makes extending the tool to different tasks merely a matter of recording a new trace.

\medskip
We proceed to demonstrate the practical utility of our methodology as applied to \gls{WCA} by setting up a series of scenarios.
We deployed a \emph{Gabriel}-powered~\cite{chen2018application} \gls{WCA} application on a small testbed consisting of
\begin{inlineenum}
    \item a server computer acting as a cloudlet
    \item a 802.11n Wi-Fi \gls{AP} connected to the cloudlet via ethernet
    \item \num{10} Android smartphones connected wirelessly to the \gls{AP}, emulating users for the application
\end{inlineenum}.
Three scenarios were considered, corresponding to setups under ideal network conditions with \num{1} and \num{10} clients, plus an additional scenario with \num{10} clients located at a distance from the \gls{AP} such that the signal strength was significantly degraded.
Each scenario was repeated a \num{100} times for statistical validity.
These setups already showcase the flexibility of our approach.




\subsection{Case study: \acsp{NCS}}\label{summary:methodology:usecase_ncs}

\todo[inline]{Discuss, at high level, the advantages of this methodology for NCSs.
Refer back to related work. }

\subsection{ExPECA Testbed \& the Ainur software stack}

After our initial implementation and experimentation with our methodology for \gls{WCA} applications, it became clear that our research would benefit greatly from the establishment of a testbed on which our methodology could be deployed.
A testbed would
\begin{inlineenum}
    \item speed up subsequent research by removing the need for ad-hoc implementations for each new study
    \item provide a standardized baseline, allowing for easier comparisons between studies.
    \todo[inline]{More}
\end{inlineenum}.
Additionally, such a testbed would benefit other research happening in the group.

These reasons led to the establishment of the \gls{EXPECA} testbed at \pgls{KTH}.
\gls{EXPECA} is a \gls{SSF}-funded infrastructure project targeting the development and provisioning of an edge computing infrastructure for research into novel applications and network architectures.
It consists of a cluster of hardware-reconfigurable \gls{COTS} computing nodes interconnected using managed switches and \glspl{SDR}.
This allows us to quickly, on-the-fly, and in an automated fashion change the characteristics of the cluster and the network, in order to study different Edge- and Cloud-computing deployments and the applications that run on them.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{publications/2022Ainur/figures/network}
    \caption{
        Prototype architecture of \acs{EXPECA}.
        Figure originally published in \cref{paper:olguinmunoz2022ainur}.
    }\label{fig:expeca}
\end{figure}

The initial prototype architecture of \gls{EXPECA} is illustrated in \cref{fig:expeca}.
\emph{Workload hosts} act as client-side user devices;
in our prototype, these corresponded to \num{10} Raspberry Pi 4 Model B boards.
These devices connect to either a cloudlet or cloud computing instances over the \emph{workload data network}.
Through clever configuration of \acsp{VLAN} and routing, traffic on this network can be forced to flow through the attached \acsp{SDR} and their associated radio processing hosts.
This allows us to seamlessly switch out the physical layer for experiments.
We implemented configurations wherein one of the \glspl{SDR} acted as a 4G or 5G base station and the other one as a cellular client.
An alternative setup had the workload hosts connect wirelessly via Wi-Fi to one of the radios acting as an \gls{AP}
Finally, the \emph{control network} is used for the out-of-band configuration of testbed resources, and the \acs{VPN} links allow direct tunneled connections to cloud compute nodes on \acs{AWS}.

The above prototype was formally introduced in \cref{paper:olguinmunoz2022ainur}, together with the software framework we developed for its automation and experiment orchestration, \emph{Ainur}.
Ainur is a highly flexible end-to-end wireless network testbed management framework.
Its objective is to facilitate the study of the effects of communication and computation elements on the performance of distributed applications.
To achieve this, Ainur provides a Python \gls{API} that allows researchers to describe experiments in a procedural manner, with plans to eventually offer toolkits for declarative configuration.

The architecture of Ainur closely resembles the conceptual layers of the \acs{TCP}/\acs{IP} stack, and the framework utilizes containerization throughout.
This includes the deployment and orchestration of workloads, support for different physical layer configurations, and automated collection of logs.
To support this, the framework leverages Docker Swarm~\cite{docker,merkel2014docker,Swarm2021} as the container orchestration layer.
Docker Swarm was chosen for its lightweight nature, simple configuration, and inclusion in the default Docker runtime installation.
This allows Ainur to remain agnostic to the nature of the workloads and support a wide range of applications and system architectures, without having to consider library dependencies.

Ainur also leverages containerization for the communication stack, which can nowadays be deployed on general-purpose processors using \gls{O-RAN} and \glspl{SDR}.
This allows for the distribution of the communication stack across multiple hosts, providing researchers with the ability to study the effects of communication and computation elements on the performance of distributed applications.

Both Ainur and \gls{EXPECA} were utilized in \cref{paper:olguinmunoz2022cleave,paper:olguinmunoz2023realistic}.
\todo[inline]{finish}
